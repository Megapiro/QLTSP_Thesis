{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Lines Importance as Charge on each Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries needed to represent the tsp and to embed it on the quantum annealer\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "from neal import SimulatedAnnealingSampler\n",
    "\n",
    "import numpy as np\n",
    "import dimod\n",
    "import itertools \n",
    "import minorminer\n",
    "import networkx as nx\n",
    "import dwave_networkx as dnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem parameters\n",
    "PROBLEM_NAME = 'tsp4.txt'\n",
    "TOKEN = ''\n",
    "CHAIN_STRENGTH = 2.0\n",
    "\n",
    "D = np.loadtxt('Test_Problems/last_tests/' + PROBLEM_NAME, dtype='i', delimiter=' ')\n",
    "Q = [80, 80, 40, 40, 20, 20, 10, 10]\n",
    "\n",
    "n = D.shape[0]\n",
    "num_reads = 10000    # num_reads must be between [1, 10000] for execution on QPU\n",
    "\n",
    "print(f'D is: \\n{D}')\n",
    "print(f'Q is: \\n{Q}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization factors\n",
    "\n",
    "# importance of constraints are set by using A,B,C in this way:\n",
    "# 0 < C * max(Qv - Qu)^2 < A\n",
    "# 0 < B * max(Duv) < C\n",
    "\n",
    "# A_NORMALIZATION = 1\n",
    "# C_NORMALIZATION = A_NORMALIZATION /  (np.max(Q) - np.min(Q)**2)\n",
    "# B_NORMALIZATION = C_NORMALIZATION / (np.max(D) + 1)\n",
    "\n",
    "# B_NORMALIZATION = 1\n",
    "# C_NORMALIZATION = (B_NORMALIZATION * np.max(D)) + 1\n",
    "# A_NORMALIZATION = C_NORMALIZATION * (np.max(Q) - np.min(Q))**2 + 1\n",
    "\n",
    "A_NORMALIZATION = 1\n",
    "B_NORMALIZATION = 0.001\n",
    "C_NORMALIZATION = 0.9\n",
    "D_NORMALIZATION = 0.00025\n",
    "\n",
    "print(A_NORMALIZATION, B_NORMALIZATION, C_NORMALIZATION, D_NORMALIZATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqubo import Binary, Constraint, Array\n",
    "\n",
    "x = Array.create('x', (n,n), 'BINARY')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_a1 = 0\n",
    "for v in range(n):\n",
    "    H_temp = 1\n",
    "    for j in range(n):\n",
    "        H_temp -= x[v, j]\n",
    "\n",
    "    H_a1 += H_temp * H_temp\n",
    "\n",
    "H_a2 = 0\n",
    "for j in range(n):\n",
    "    H_temp = 1\n",
    "    for v in range(n):\n",
    "        H_temp -= x[v, j]\n",
    "\n",
    "    H_a2 += H_temp * H_temp\n",
    "\n",
    "H_a3 = 0\n",
    "for u in range(n):\n",
    "    for v in range(n):\n",
    "            k = 1\n",
    "            for j in range(n):\n",
    "                H_a3 +=  x[u, j] * x[v, k]\n",
    "\n",
    "                k += 1\n",
    "                if k == n: k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_b = 0\n",
    "\n",
    "for u in range(n):\n",
    "    for v in range(n):\n",
    "        k = 1\n",
    "        for j in range(n):\n",
    "            H_b +=  D[u,v] * x[u, j] * x[v, k]\n",
    "\n",
    "            k += 1\n",
    "            if k == n: k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_c = 0\n",
    "\n",
    "for v in range(n):\n",
    "    if v % 2 == 0:\n",
    "        for u in range(n):\n",
    "            if u != v + 1 and u != v:\n",
    "                H_c += x[v, 0] * x[u, 1]\n",
    "    else:\n",
    "        for u in range(n):\n",
    "            if u != v - 1 and u != v:\n",
    "                H_c += x[v, 0] * x[u, 1]\n",
    "\n",
    "H_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_d = 0\n",
    "\n",
    "for u in range(n):\n",
    "    for v in range(n):\n",
    "        k = 1\n",
    "        for j in range(n - 1):\n",
    "            H_d += x[u, j] * x[v, k] * ((Q[v] - Q[u])**2)\n",
    "\n",
    "            k += 1\n",
    "            if k == n: k = 0\n",
    "\n",
    "H_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_A = A_NORMALIZATION * H_a1 + A_NORMALIZATION * H_a2 #+ A_NORMALIZATION * H_a3\n",
    "H_B = B_NORMALIZATION * H_b\n",
    "H_C = C_NORMALIZATION * H_c     # H_C is not needed anymore with H_D ranging up to j - 1\n",
    "H_D = D_NORMALIZATION * H_d\n",
    "\n",
    "H = H_A + H_B + H_D\n",
    "\n",
    "model = H.compile()\n",
    "qubo, _= model.to_qubo()\n",
    "\n",
    "BQM = dimod.BinaryQuadraticModel.from_qubo(qubo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows to visualize the built matrix\n",
    "\n",
    "Q = np.zeros((n**2,n**2))\n",
    "k = np.zeros((2,2))\n",
    "\n",
    "np.set_printoptions(linewidth=100)\n",
    "\n",
    "for key in qubo:\n",
    "    Q[int((key[0])[2]) * n + int((key[0])[5]), int((key[1])[2]) * n + int((key[0])[5])] = qubo[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response_data(response):\n",
    "    pos_sets = []\n",
    "    response = response.lowest()\n",
    "    # ------- Print results to user -------\n",
    "    print('-' * 100)\n",
    "    print('{:>20s}{:>42s}{:>22s}'.format('Set 1','Energy',\"Count\"))\n",
    "    print('-' * 100)\n",
    "    for sample, E, occ in response.data(fields=['sample','energy',\"num_occurrences\"]):\n",
    "        S0 = [k for k,v in sample.items() if v == 0]\n",
    "        S1 = [k for k,v in sample.items() if v == 1]\n",
    "        pos_sets.append(S1)\n",
    "        print('{:>30s}{:^30s}{:^15s}'.format(str(S1),str(E),str(occ)))\n",
    "    \n",
    "    return pos_sets\n",
    "\n",
    "def map_variables(pos_set):\n",
    "    m_set = []\n",
    "    for i in range(len(pos_set)):\n",
    "        x = pos_set[i].replace(']', '').split('[')\n",
    "        m_set.append([int(x[1]), int(x[2])])\n",
    "    \n",
    "    return m_set\n",
    "\n",
    "def return_solution(pos_solution):\n",
    "    sol_num = 0\n",
    "    for p_set in pos_solution:\n",
    "        bool = True\n",
    "        m_set = map_variables(p_set)\n",
    "        s_res = sorted(m_set, key=lambda x: x[1])\n",
    "\n",
    "        if ((s_res[0])[0] % 2) == 0:\n",
    "            if ((s_res[0])[0] + 1) != (s_res[1])[0]:\n",
    "                bool = False\n",
    "        else:\n",
    "            if ((s_res[0])[0] - 1) != (s_res[1])[0]:\n",
    "                bool = False\n",
    "        \n",
    "        if bool:\n",
    "            sol_num += 1\n",
    "            for i in range(len(s_res) - 1):\n",
    "                print((s_res[i])[0], end='-->')\n",
    "            \n",
    "            print((s_res[len(s_res) - 1])[0])\n",
    "\n",
    "    return sol_num\n",
    "\n",
    "def complete_return_solution(pos_solution):\n",
    "    sol_num = 0\n",
    "    for p_set in pos_solution:\n",
    "        sol_num += 1\n",
    "        m_set = map_variables(p_set)\n",
    "        s_res = sorted(m_set, key=lambda x: x[1])\n",
    "        for i in range(len(s_res) - 1):\n",
    "            print((s_res[i])[0], end='-->')\n",
    "        \n",
    "        print((s_res[len(s_res) - 1])[0])\n",
    "    \n",
    "    return sol_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_solution(pos_sets):\n",
    "    wrong_sol = False\n",
    "\n",
    "    for p_set in pos_sets:\n",
    "        correct = True\n",
    "        m_set = map_variables(p_set)\n",
    "        s_res = sorted(m_set, key=lambda x: x[1])\n",
    "\n",
    "        for i in range(0, int(len(s_res)/2), 2):\n",
    "            start_node = (s_res[i + 0])[0]\n",
    "            end_node = (s_res[i + 1])[0]\n",
    "            \n",
    "            if(start_node % 2) == 0:\n",
    "                if (start_node + 1) != end_node:\n",
    "                    correct = False\n",
    "            else:\n",
    "                if (start_node - 1) != end_node:\n",
    "                    correct = False\n",
    "\n",
    "        if not correct:\n",
    "            wrong_sol = True\n",
    "            print('Wrong solution:')\n",
    "            for i in range(len(s_res) - 1):\n",
    "                print((s_res[i])[0], end='-->')\n",
    "        \n",
    "            print((s_res[len(s_res) - 1])[0])\n",
    "\n",
    "    return wrong_sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SimulatedAnnealingSampler()\n",
    "\n",
    "response_SA = sampler.sample(BQM, num_reads = num_reads, chain_strength = CHAIN_STRENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_SA = print_response_data(response_SA.aggregate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not check_solution(solution_SA):\n",
    "    sol_num_SA = return_solution(solution_SA)\n",
    "    print(f'There are {sol_num_SA} CORRECT solutions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sol_num_SA = complete_return_solution(solution_SA)\n",
    "print(f'There are {all_sol_num_SA} solutions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = EmbeddingComposite(DWaveSampler(token=TOKEN))\n",
    "\n",
    "response_QPU = sampler.sample(BQM, num_reads=num_reads, label='tsp6.txt for thesis', chain_strength=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_QPU = print_response_data(response_QPU.aggregate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not check_solution(solution_QPU):\n",
    "    sol_num_QPU = return_solution(solution_QPU)\n",
    "    print(f'There are {sol_num_QPU} solutions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sol_num_QPU = complete_return_solution(solution_QPU)\n",
    "print(f'There are {all_sol_num_QPU} solutions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Energy distribution of the two solvers to compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "num_bins = 100\n",
    "use_bin = 50\n",
    "\n",
    "def histogram_energies(sampleset_SA, sampleset_QPU):\n",
    "    \"Plot energy histograms for both QPUs.\"\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    SA = sampleset_SA.record.energy\n",
    "    QPU = sampleset_QPU.record.energy\n",
    "\n",
    "    bins=np.histogram(np.hstack((SA,QPU)), bins=num_bins)[1]\n",
    "\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    ax.hist(SA, bins[0:use_bin], color='g', alpha=0.4, label=\"SA\")\n",
    "    ax.hist(QPU, bins[0:use_bin], color='r', alpha=0.4, label=\"QPU\")\n",
    "\n",
    "    ax.set_xlabel(\"Energy\")\n",
    "    ax.set_ylabel(\"Samples\")\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_energies(response_SA, response_QPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Strength Analysis - Uniform Torque Compensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dwave.embedding.chain_strength import uniform_torque_compensation\n",
    "\n",
    "int_list = random.sample(range(500, 2000), 10)\n",
    "prefactor_list = [x/1000 for x in int_list]\n",
    "prefactor_list.insert(0, 1.414)\n",
    "\n",
    "chain_strengths = []\n",
    "for prefactor in prefactor_list:\n",
    "    cs = uniform_torque_compensation(BQM, embedding=EmbeddingComposite(DWaveSampler(token=TOKEN)), prefactor=prefactor)\n",
    "    chain_strengths.append(cs)\n",
    "\n",
    "\n",
    "print(prefactor_list)\n",
    "print(chain_strengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the embedded graph on the architecture of the solver used in the real annealing\n",
    "\n",
    "device = DWaveSampler(token=TOKEN)\n",
    "device.solver.data['id']\n",
    "\n",
    "QUBO_graph = BQM.to_networkx_graph()\n",
    "QPU_graph = device.solver.data['properties'][\"couplers\"]\n",
    "\n",
    "embedded_graph = minorminer.find_embedding(QUBO_graph.edges(), QPU_graph)\n",
    "\n",
    "embedded_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of qubit required in the embedding and the minimal and maximal length of the chains created\n",
    "\n",
    "sublist = [values for keys, values in embedded_graph.items()]\n",
    "flat_list = set(itertools.chain(*sublist))    \n",
    "\n",
    "max_chain_length = None\n",
    "min_chain_length = None\n",
    "\n",
    "for _, chain in embedded_graph.items():\n",
    "    if max_chain_length is None:\n",
    "        max_chain_length = len(chain)\n",
    "        min_chain_length = len(chain)\n",
    "\n",
    "    if len(chain) > max_chain_length:\n",
    "        max_chain_length = len(chain)\n",
    "\n",
    "    if len(chain) < min_chain_length:\n",
    "        min_chain_length = len(chain)\n",
    "\n",
    "    \n",
    "print(\"Embedding requires {} qubits and has chain lengths between {}-{}\".format(len(flat_list),min_chain_length, max_chain_length))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b25f51ef85160de9a965b67685c52ff5d6062ed6f6f2ddc05da5ec639e0d94c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
